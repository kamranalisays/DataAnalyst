{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNIwe5N7s0e_"
   },
   "source": [
    "# Real-world Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDYDkH-Zs7Nn"
   },
   "source": [
    "## 1. Gather data\n",
    "\n",
    "In this section, you will extract data using two different data gathering methods and combine the data. Use at least two different types of data-gathering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbN7z7rcuqpO"
   },
   "source": [
    "### **1.1.** Problem Statement\n",
    "In 2-4 sentences, explain the kind of problem you want to look at and the datasets you will be wrangling for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gi6swhjSYqu2",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Answers **\n",
    "\n",
    "  In todays world global warming is the main problem and we address this problem by research questions.\n",
    "\n",
    "Following are the research question:\n",
    "\n",
    "(1)Identify the trend in temperature  over the time of 22 years\n",
    "\n",
    "(2) Identify the trend in  Carbon monoxide  over the  22 years period "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e6gS0wL1KTu"
   },
   "source": [
    "# **Dataset 1**\n",
    "\n",
    "Q1 Why you picked the dataset\n",
    "\n",
    "Q2 The gathering method\n",
    "\n",
    "Q3 The names and significance of the variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "(1) I picked the Seoul Weather Data because i want to see rise of temperature over the time.\n",
    "\n",
    "(2) Data gathered from web \n",
    "URL =  'https://www.kaggle.com/api/v1/datasets/download/alfredkondoro/seoul-historical-weather-data-2024'\n",
    "\n",
    "(3) As we interested in temperature changes over the time therefore following varaiables selected.\n",
    "\n",
    "1-  Temp Variable :  which shows the temperature \n",
    "\n",
    "2-  Datetime Variable : which the date at which the temperature is recorded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Su8E0uLuYkHU"
   },
   "outputs": [],
   "source": [
    "#1st data gathering and loading method\n",
    "\n",
    "############################## First DataSet #########################################\n",
    "# Seoul Weather Data load from url\n",
    "# url return a zip file containing csv files\n",
    "\n",
    "import requests as req\n",
    "import zipfile as zf\n",
    "from io import BytesIO \n",
    "\n",
    "url =  'https://www.kaggle.com/api/v1/datasets/download/alfredkondoro/seoul-historical-weather-data-2024'\n",
    "response = req.get(url)\n",
    "\n",
    "with zf.ZipFile(BytesIO(response.content)) as z:\n",
    "    file_list = z.namelist()\n",
    "   # print('files in zip =', file_list )\n",
    "\n",
    "    csv_files = [ f  for f in file_list if f.endswith('.csv') ]\n",
    "\n",
    "    count=len(csv_files)\n",
    "    raw_df_wd = pd.DataFrame()\n",
    "    i=0;\n",
    "    \n",
    "    while count > 0 :\n",
    "        count= count -1\n",
    "        if csv_files:\n",
    "            with z.open(csv_files[i]) as f:\n",
    "                temp_df = pd.read_csv(f)\n",
    "                raw_df_wd = pd.concat([raw_df_wd , temp_df] , ignore_index = True)\n",
    "                i =i+1\n",
    "        else:\n",
    "            print(\"No CSV files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting raw weather data to CSV\n",
    "raw_df_wd.to_csv('raw_df_wd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning raw dataframe to new variable \n",
    "inprocess_df_wd=raw_df_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>severerisk</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>moonphase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>description</th>\n",
       "      <th>icon</th>\n",
       "      <th>stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10971</th>\n",
       "      <td>seoul</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>84.7</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2024-01-01T07:46:50</td>\n",
       "      <td>2024-01-01T17:23:42</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>47111099999,47098099999,47112099999,4711909999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>seoul</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>94.7</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2023-12-31T07:46:38</td>\n",
       "      <td>2023-12-31T17:22:57</td>\n",
       "      <td>0.63</td>\n",
       "      <td>Snow, Rain, Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day with a chance...</td>\n",
       "      <td>rain</td>\n",
       "      <td>47111099999,47098099999,47112099999,4711909999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>seoul</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>90.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2023-12-30T07:46:24</td>\n",
       "      <td>2023-12-30T17:22:12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Snow, Rain, Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day with rain or ...</td>\n",
       "      <td>snow</td>\n",
       "      <td>47111099999,47098099999,47112099999,4711909999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10968</th>\n",
       "      <td>seoul</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>70.2</td>\n",
       "      <td>...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2023-12-29T07:46:08</td>\n",
       "      <td>2023-12-29T17:21:29</td>\n",
       "      <td>0.57</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>47111099999,47098099999,47112099999,4711909999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10967</th>\n",
       "      <td>seoul</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>71.5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2023-12-28T07:45:50</td>\n",
       "      <td>2023-12-28T17:20:48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>47111099999,47098099999,47112099999,4711909999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        name    datetime  tempmax  tempmin  temp  feelslikemax  feelslikemin  \\\n",
       "10971  seoul  2024-01-01      7.3     -0.2   3.0           6.6          -2.8   \n",
       "10970  seoul  2023-12-31      4.4      0.8   2.3           3.1          -1.8   \n",
       "10969  seoul  2023-12-30      1.9     -0.9   0.5          -1.2          -3.5   \n",
       "10968  seoul  2023-12-29      4.5     -1.4   1.5           3.0          -3.5   \n",
       "10967  seoul  2023-12-28      4.1     -1.7   1.1           2.4          -3.4   \n",
       "\n",
       "       feelslike  dew  humidity  ...  solarenergy  uvindex  severerisk  \\\n",
       "10971        1.7  0.5      84.7  ...          8.6      5.0        10.0   \n",
       "10970        0.4  1.5      94.7  ...          4.5      4.0        10.0   \n",
       "10969       -2.4 -1.0      90.1  ...          1.8      1.0        10.0   \n",
       "10968       -0.1 -3.3      70.2  ...          8.8      4.0        10.0   \n",
       "10967        0.0 -3.7      71.5  ...          9.6      5.0        10.0   \n",
       "\n",
       "                   sunrise               sunset  moonphase  \\\n",
       "10971  2024-01-01T07:46:50  2024-01-01T17:23:42       0.66   \n",
       "10970  2023-12-31T07:46:38  2023-12-31T17:22:57       0.63   \n",
       "10969  2023-12-30T07:46:24  2023-12-30T17:22:12       0.60   \n",
       "10968  2023-12-29T07:46:08  2023-12-29T17:21:29       0.57   \n",
       "10967  2023-12-28T07:45:50  2023-12-28T17:20:48       0.54   \n",
       "\n",
       "                         conditions  \\\n",
       "10971              Partially cloudy   \n",
       "10970  Snow, Rain, Partially cloudy   \n",
       "10969  Snow, Rain, Partially cloudy   \n",
       "10968              Partially cloudy   \n",
       "10967              Partially cloudy   \n",
       "\n",
       "                                             description               icon  \\\n",
       "10971                  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "10970  Partly cloudy throughout the day with a chance...               rain   \n",
       "10969  Partly cloudy throughout the day with rain or ...               snow   \n",
       "10968                  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "10967                  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "\n",
       "                                                stations  \n",
       "10971  47111099999,47098099999,47112099999,4711909999...  \n",
       "10970  47111099999,47098099999,47112099999,4711909999...  \n",
       "10969  47111099999,47098099999,47112099999,4711909999...  \n",
       "10968  47111099999,47098099999,47112099999,4711909999...  \n",
       "10967  47111099999,47098099999,47112099999,4711909999...  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing five rows \n",
    "inprocess_df_wd.sort_values(by='datetime', ascending= False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tempmax</th>\n",
       "      <th>tempmin</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>severerisk</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>moonphase</th>\n",
       "      <th>conditions</th>\n",
       "      <th>description</th>\n",
       "      <th>icon</th>\n",
       "      <th>stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seoul</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>35.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>26.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>65.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-01T07:46:54</td>\n",
       "      <td>1994-01-01T17:23:56</td>\n",
       "      <td>0.61</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>47111099999,47112099999,47120099999,4711009999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seoul</td>\n",
       "      <td>1994-01-02</td>\n",
       "      <td>43.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>36.2</td>\n",
       "      <td>39.4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>32.6</td>\n",
       "      <td>27.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-02T07:47:03</td>\n",
       "      <td>1994-01-02T17:24:44</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>47111099999,47112099999,47120099999,4711009999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seoul</td>\n",
       "      <td>1994-01-03</td>\n",
       "      <td>47.9</td>\n",
       "      <td>30.9</td>\n",
       "      <td>38.0</td>\n",
       "      <td>44.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>35.4</td>\n",
       "      <td>27.3</td>\n",
       "      <td>68.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-03T07:47:11</td>\n",
       "      <td>1994-01-03T17:25:33</td>\n",
       "      <td>0.68</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>47111099999,47112099999,47120099999,4711009999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seoul</td>\n",
       "      <td>1994-01-04</td>\n",
       "      <td>38.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>26.3</td>\n",
       "      <td>13.6</td>\n",
       "      <td>51.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-04T07:47:16</td>\n",
       "      <td>1994-01-04T17:26:23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Clear conditions throughout the day.</td>\n",
       "      <td>clear-day</td>\n",
       "      <td>47111099999,47112099999,47120099999,4711009999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seoul</td>\n",
       "      <td>1994-01-05</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>63.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-05T07:47:19</td>\n",
       "      <td>1994-01-05T17:27:14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Snow, Rain, Overcast</td>\n",
       "      <td>Cloudy skies throughout the day with late afte...</td>\n",
       "      <td>rain</td>\n",
       "      <td>47111099999,47112099999,47120099999,4711009999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    name    datetime  tempmax  tempmin  temp  feelslikemax  feelslikemin  \\\n",
       "0  seoul  1994-01-01     35.2     16.4  26.3          33.4          13.0   \n",
       "1  seoul  1994-01-02     43.0     31.5  36.2          39.4          26.7   \n",
       "2  seoul  1994-01-03     47.9     30.9  38.0          44.7          24.5   \n",
       "3  seoul  1994-01-04     38.8     22.1  30.1          32.0          18.4   \n",
       "4  seoul  1994-01-05     40.0     24.0  33.1          40.0          18.5   \n",
       "\n",
       "   feelslike   dew  humidity  ...  solarenergy  uvindex  severerisk  \\\n",
       "0       24.3  15.5      65.9  ...          NaN      NaN         NaN   \n",
       "1       32.6  27.9      72.1  ...          NaN      NaN         NaN   \n",
       "2       35.4  27.3      68.1  ...          NaN      NaN         NaN   \n",
       "3       26.3  13.6      51.2  ...          NaN      NaN         NaN   \n",
       "4       31.0  21.7      63.9  ...          NaN      NaN         NaN   \n",
       "\n",
       "               sunrise               sunset  moonphase            conditions  \\\n",
       "0  1994-01-01T07:46:54  1994-01-01T17:23:56       0.61      Partially cloudy   \n",
       "1  1994-01-02T07:47:03  1994-01-02T17:24:44       0.65      Partially cloudy   \n",
       "2  1994-01-03T07:47:11  1994-01-03T17:25:33       0.68      Partially cloudy   \n",
       "3  1994-01-04T07:47:16  1994-01-04T17:26:23       0.72                 Clear   \n",
       "4  1994-01-05T07:47:19  1994-01-05T17:27:14       0.75  Snow, Rain, Overcast   \n",
       "\n",
       "                                         description               icon  \\\n",
       "0                  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "1                  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "2                  Partly cloudy throughout the day.  partly-cloudy-day   \n",
       "3               Clear conditions throughout the day.          clear-day   \n",
       "4  Cloudy skies throughout the day with late afte...               rain   \n",
       "\n",
       "                                            stations  \n",
       "0  47111099999,47112099999,47120099999,4711009999...  \n",
       "1  47111099999,47112099999,47120099999,4711009999...  \n",
       "2  47111099999,47112099999,47120099999,4711009999...  \n",
       "3  47111099999,47112099999,47120099999,4711009999...  \n",
       "4  47111099999,47112099999,47120099999,4711009999...  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inprocess_df_wd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoUjq1tPzz7P"
   },
   "source": [
    "# Dataset 2\n",
    "\n",
    "Q1 Why you picked the dataset\n",
    "\n",
    "Q2 The gathering method\n",
    "\n",
    "Q3 The names and significance of the variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "(1) I picked the air pollution dataset to see the rise in carbon monoxide(CO)  level in Seoul Air over the time.\n",
    "\n",
    "(2) Reading from CSV file\n",
    "\n",
    "(3) As we interested in CO level changes over the time therefore following varaiables selected.\n",
    "\n",
    "1-  co Variable :  which shows the co value \n",
    "\n",
    "2-  dt Variable : which shows the date at which the co value is recorded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6zT0QxRyYmm7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>loc</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>co</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>103</td>\n",
       "      <td>37.540037</td>\n",
       "      <td>127.002661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>105</td>\n",
       "      <td>37.593730</td>\n",
       "      <td>126.947561</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.055</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>107</td>\n",
       "      <td>37.542043</td>\n",
       "      <td>127.047497</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.046</td>\n",
       "      <td>13.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>108</td>\n",
       "      <td>37.547185</td>\n",
       "      <td>127.090304</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.034</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>113</td>\n",
       "      <td>37.654140</td>\n",
       "      <td>127.026801</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.039</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  loc        lat        long    so2    no2    co     o3  pm10  \\\n",
       "0  1988010100  103  37.540037  127.002661    NaN  0.007  10.3  0.000   NaN   \n",
       "1  1988010100  105  37.593730  126.947561  0.340  0.055  12.6  0.043   NaN   \n",
       "2  1988010100  107  37.542043  127.047497  0.399  0.046  13.4    NaN   NaN   \n",
       "3  1988010100  108  37.547185  127.090304  0.261  0.034   5.4  0.000   NaN   \n",
       "4  1988010100  113  37.654140  127.026801  0.443  0.039  14.6  0.000   NaN   \n",
       "\n",
       "   pm2.5  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2nd data gathering and loading method\n",
    "\n",
    "\n",
    "############################### Second Dataset ######################\n",
    "### Air Pollution Dataset\n",
    "\n",
    "raw_df_pd = pd.read_csv('seoul_air_1988_2021.csv')\n",
    "raw_df_pd.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional data storing step: You may save your raw dataset files to the local data store before moving to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting raw pollution data to CSV\n",
    "raw_df_pd.to_csv('raw_df_pd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning weather raw data to other variable\n",
    "inprocess_df_pd=raw_df_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwSWIVmotLgV"
   },
   "source": [
    "## 2. Assess data\n",
    "\n",
    "## 1-Weather Data\n",
    "\n",
    "Assess the data according to data quality and tidiness metrics using the report below.\n",
    "\n",
    "List **two** data quality issues and **two** tidiness issues. Assess each data issue visually **and** programmatically, then briefly describe the issue you find.  **Make sure you include justifications for the methods you use for the assessment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adaK2iPNzVu4"
   },
   "source": [
    "### Quality Issue 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-qfcocStzsKg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                    0\n",
       "datetime                0\n",
       "tempmax                 0\n",
       "tempmin                 0\n",
       "temp                    0\n",
       "feelslikemax            0\n",
       "feelslikemin            0\n",
       "feelslike               0\n",
       "dew                     0\n",
       "humidity                0\n",
       "precip                  0\n",
       "precipprob              0\n",
       "precipcover             0\n",
       "preciptype           6923\n",
       "snow                 2926\n",
       "snowdepth            2717\n",
       "windgust             7325\n",
       "windspeed               0\n",
       "winddir                 0\n",
       "sealevelpressure        0\n",
       "cloudcover              0\n",
       "visibility              0\n",
       "solarradiation       5851\n",
       "solarenergy          5851\n",
       "uvindex              5851\n",
       "severerisk          10250\n",
       "sunrise                 0\n",
       "sunset                  0\n",
       "moonphase               0\n",
       "conditions              0\n",
       "description             0\n",
       "icon                    0\n",
       "stations                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the dataframe \n",
    "inprocess_df_wd.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The above visual shows the total number of missing values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Be77N4I1AmE"
   },
   "source": [
    "### Quality Issue 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bnviRCUI-bb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Inspecting the dataframe \n",
    "inprocess_df_wd.duplicated().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# the above value shows the total number duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXhGiYyiwwKN"
   },
   "source": [
    "### Tidiness Issue 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BTuQw7Rbsio4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        47111099999,47112099999,47120099999,4711009999...\n",
       "1        47111099999,47112099999,47120099999,4711009999...\n",
       "2        47111099999,47112099999,47120099999,4711009999...\n",
       "3        47111099999,47112099999,47120099999,4711009999...\n",
       "4        47111099999,47112099999,47120099999,4711009999...\n",
       "                               ...                        \n",
       "10967    47111099999,47098099999,47112099999,4711909999...\n",
       "10968    47111099999,47098099999,47112099999,4711909999...\n",
       "10969    47111099999,47098099999,47112099999,4711909999...\n",
       "10970    47111099999,47098099999,47112099999,4711909999...\n",
       "10971    47111099999,47098099999,47112099999,4711909999...\n",
       "Name: stations, Length: 10972, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the dataframe \n",
    "inprocess_df_wd['stations']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#  you can see above the multiple values in one column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ffMoRGSwzYj"
   },
   "source": [
    "### Tidiness Issue 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "c8JK4DoXxtFA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the dataframe programmatically\n",
    "\n",
    "print(inprocess_df_wd['datetime'].dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# After the execution of above command , you can see the datatype of the column is object instead of datatime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6gmLnBttpCh"
   },
   "source": [
    "## 3. Clean data\n",
    "Clean the data to solve the 4 issues corresponding to data quality and tidiness found in the assessing step. **Make sure you include justifications for your cleaning decisions.**\n",
    "\n",
    "After the cleaning for each issue, please use **either** the visually or programatical method to validate the cleaning was succesful.\n",
    "\n",
    "At this stage, you are also expected to remove variables that are unnecessary for your analysis and combine your datasets. Depending on your datasets, you may choose to perform variable combination and elimination before or after the cleaning stage. Your dataset must have **at least** 4 variables after combining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of the datasets to ensure the raw dataframes \n",
    "# are not impacted\n",
    "\n",
    "cleaning_df_wd = inprocess_df_wd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmFhN52Yyn3l"
   },
   "source": [
    "### **Quality Issue 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9UejDWrNMW4a"
   },
   "outputs": [],
   "source": [
    "# Apply the cleaning strategy\n",
    "# no need of following variables/columns  for analysis\n",
    "\n",
    "cleaning_df_wd.drop(['preciptype', 'snow' , 'snowdepth', 'windgust', 'solarradiation', 'solarenergy', 'uvindex' , 'severerisk' ] , axis=1 , inplace=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# irrelavent columns have been removed successful because don't need them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_DAUbJrymBL"
   },
   "source": [
    "### **Quality Issue 2: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5Yfb-Yu5MTuE"
   },
   "outputs": [],
   "source": [
    "# Apply the cleaning strategy\n",
    "\n",
    "cleaning_df_wd.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  duplicated removed successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIUrrfSNyOPR"
   },
   "source": [
    "### **Tidiness Issue 1: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "fib0zAm333bn"
   },
   "outputs": [],
   "source": [
    "# Apply the cleaning strategy\n",
    "\n",
    "cleaning_df_wd.drop('stations' , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column:stations has been removed because it contain multiple values and we don't need it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o51Bt8kwyTzk"
   },
   "source": [
    "### **Tidiness Issue 2: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7zW8O5yx4Y9O"
   },
   "outputs": [],
   "source": [
    "# Apply the cleaning strategy\n",
    "\n",
    "cleaning_df_wd['sunrise'] = pd.to_datetime(cleaning_df_wd['sunrise']) ;\n",
    "cleaning_df_wd['sunset'] = pd.to_datetime(cleaning_df_wd['sunset']) ;\n",
    "cleaning_df_wd['datetime'] = pd.to_datetime(cleaning_df_wd['datetime']) ;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "q6I_Sr7lxXi5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(cleaning_df_wd['sunrise'].dtype)\n",
    "print(cleaning_df_wd['sunset'].dtype)\n",
    "print(cleaning_df_wd['datetime'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see the the dataype have been changed from object type to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset 2 - Air Polution**\n",
    "resolve cleaning and tideness issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>loc</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>co</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>103</td>\n",
       "      <td>37.540037</td>\n",
       "      <td>127.002661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>105</td>\n",
       "      <td>37.593730</td>\n",
       "      <td>126.947561</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.055</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>107</td>\n",
       "      <td>37.542043</td>\n",
       "      <td>127.047497</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.046</td>\n",
       "      <td>13.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>108</td>\n",
       "      <td>37.547185</td>\n",
       "      <td>127.090304</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.034</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988010100</td>\n",
       "      <td>113</td>\n",
       "      <td>37.654140</td>\n",
       "      <td>127.026801</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.039</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  loc        lat        long    so2    no2    co     o3  pm10  \\\n",
       "0  1988010100  103  37.540037  127.002661    NaN  0.007  10.3  0.000   NaN   \n",
       "1  1988010100  105  37.593730  126.947561  0.340  0.055  12.6  0.043   NaN   \n",
       "2  1988010100  107  37.542043  127.047497  0.399  0.046  13.4    NaN   NaN   \n",
       "3  1988010100  108  37.547185  127.090304  0.261  0.034   5.4  0.000   NaN   \n",
       "4  1988010100  113  37.654140  127.026801  0.443  0.039  14.6  0.000   NaN   \n",
       "\n",
       "   pm2.5  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show only 5 rows \n",
    "\n",
    "cleaning_df_pd= inprocess_df_pd\n",
    "cleaning_df_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of duplicates\n",
    "cleaning_df_pd.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5984782 entries, 0 to 5984781\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   dt      int64  \n",
      " 1   loc     int64  \n",
      " 2   lat     float64\n",
      " 3   long    float64\n",
      " 4   so2     float64\n",
      " 5   no2     float64\n",
      " 6   co      float64\n",
      " 7   o3      float64\n",
      " 8   pm10    float64\n",
      " 9   pm2.5   float64\n",
      "dtypes: float64(8), int64(2)\n",
      "memory usage: 456.6 MB\n"
     ]
    }
   ],
   "source": [
    "cleaning_df_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Issue 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt             0\n",
       "loc            0\n",
       "lat            0\n",
       "long           0\n",
       "so2       117565\n",
       "no2       128616\n",
       "co        161948\n",
       "o3        108206\n",
       "pm10      947434\n",
       "pm2.5    2228730\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the following command shows the total number of null values in each column\n",
    "cleaning_df_pd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as you can see above the total number of null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing last two digit in date column because we don't need them\n",
    "cleaning_df_pd['dt'] =cleaning_df_pd['dt'].astype(str).str[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to datetime\n",
    "\n",
    "cleaning_df_pd['dt'] =pd.to_datetime(cleaning_df_pd['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping null \n",
    "cleaning_df_pd = cleaning_df_pd.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are multiple locations , removing all location except 103 to align the date column with another dataset\n",
    "\n",
    "cleaning_df_pd = cleaning_df_pd[ cleaning_df_pd['loc'] == 103 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates \n",
    "cleaning_df_pd.drop_duplicates(subset=['dt', 'loc', 'lat', 'long'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting values by dt column\n",
    "cleaning_df_pd.sort_values(by='dt' , ascending=True ).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df_pd.sort_values(by='dt' , ascending=False ).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of rows in pollution dataset\n",
    "row_count = len(cleaning_df_pd)\n",
    "row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df_pd.sort_values(by='dt', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting first row of every month in dataset\n",
    "cleaning_df_pd = cleaning_df_pd.groupby( (cleaning_df_pd['dt']).dt.to_period('M')).first().reset_index(drop=True)\n",
    "cleaning_df_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of rows in pollution dataset\n",
    "row_count = len(cleaning_df_pd)\n",
    "row_count \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove unnecessary variables and combine datasets**\n",
    "\n",
    "Depending on the datasets, you can also peform the combination before the cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df_wd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  filtering out columns so that we have only columns that we need in the weather data\n",
    "cleaning_df_wd = cleaning_df_wd[['name' , 'datetime' , 'temp']] \n",
    "cleaning_df_wd.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df_wd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the column\n",
    "cleaning_df_wd =cleaning_df_wd.rename(columns={'datetime':'date'} )\n",
    "cleaning_df_wd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date\n",
    "cleaning_df_wd = cleaning_df_wd.sort_values('date', ascending= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the first entry of every month\n",
    "cleaning_df_wd = cleaning_df_wd.groupby(cleaning_df_wd['date'].dt.to_period('M')).first().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the weather data \n",
    "# We have Air pollution data from 2001-8-8 to 2021-12-31\n",
    "\n",
    "cleaning_df_wd = cleaning_df_wd[ ( cleaning_df_wd['date'].dt.year >= 2001 ) & ( cleaning_df_wd['date'].dt.year <= 2021 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  starting date in the weather data 2001-01-01\n",
    "cleaning_df_wd.sort_values( by='date', ascending=True).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out the data\n",
    "cleaning_df_wd = cleaning_df_wd[cleaning_df_wd['date'] >= '2001-08-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  last date in the weather data 2021-11-01\n",
    "cleaning_df_wd.sort_values( by='date', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df_wd['date'] = cleaning_df_wd['date'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df_wd.sort_values( by='date', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count= len(cleaning_df_wd)\n",
    "print('total rows in weather data =',row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count= len(cleaning_df_pd)\n",
    "print('total rows in Pollution data =',row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelavent columns loc , lat , long\n",
    "cleaning_df_pd.drop(columns=['loc', 'lat', 'long'],inplace=True)\n",
    "cleaning_df_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  starting date in the pollution data 2001-8-8\n",
    "cleaning_df_pd.sort_values( by='dt', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last date in the polution 2021-12-31\n",
    "cleaning_df_pd.sort_values( by='dt', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df_pd['dt'] = cleaning_df_pd['dt'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df_pd = cleaning_df_pd.rename(columns =  {'dt' : 'date' } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_df_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = len(cleaning_df_pd)\n",
    "print(row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inner join on the 'date' column\n",
    "combined_df = pd.merge(\n",
    "    cleaning_df_wd,\n",
    "    cleaning_df_pd,\n",
    "    on='date',\n",
    "    how='inner'  # This is the crucial change for inner join\n",
    ")\n",
    "\n",
    "# Verify the results\n",
    "print(f\"Number of rows after inner join: {len(combined_df)}\")\n",
    "print(\"Sample of combined data:\")\n",
    "print(combined_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F42urHuzttjF"
   },
   "source": [
    "## 4. Update your data store\n",
    "Update your local database/data store with the cleaned data, following best practices for storing your cleaned data:\n",
    "\n",
    "- Must maintain different instances / versions of data (raw and cleaned data)\n",
    "- Must name the dataset files informatively\n",
    "- Ensure both the raw and cleaned data is saved to your database/data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export to CSV\n",
    "combined_df.to_csv('combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGy_yddGtzhM"
   },
   "source": [
    "## 5. Answer the research question\n",
    "\n",
    "### **5.1:** Define and answer the research question \n",
    "Going back to the problem statement in step 1, use the cleaned data to answer the question you raised. Produce **at least** two visualizations using the cleaned data and explain how they help you answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lkw3rW9kZmOm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visual 1 \n",
    "\n",
    "df = combined_df[pd.to_datetime(combined_df['date']).dt.month == 6]\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(df['date'], df['temp'], 'r')\n",
    "plt.title('Temperature Level')\n",
    "plt.ylabel('temperature')\n",
    "plt.xlabel('date')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  \n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Research questions is \n",
    "1)Identify the trend in temperature over the time of 22 years \n",
    "\n",
    "The current graph do not reflect the consistent trend(upward or downward) in temperature therefore need more datasets for meaningful results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fdK_8ZGZm9R"
   },
   "outputs": [],
   "source": [
    "df = combined_df[pd.to_datetime(combined_df['date']).dt.month == 6]\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(df['date'], df['co'], 'b')\n",
    "plt.title('Level of CO in June')\n",
    "plt.ylabel('CO')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5RgvMGUZoHn"
   },
   "source": [
    "My Research questions is \n",
    "1)Identify the trend in CO over the time of 22 years \n",
    "\n",
    "The current graph do not reflect the consistent trend(upward or downward) in CO therefore need more datasets for meaningful results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ezWXXZVj-TP"
   },
   "source": [
    "### **5.2:** Reflection\n",
    "In 2-4 sentences, if you had more time to complete the project, what actions would you take? For example, which data quality and structural issues would you look into further, and what research questions would you further explore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current graphs do not reflect the expected trends(upward or downward) in temperature and CO over the 22-year period. If i have more time , i will download and compare additional datasets from reliable sources to validate and refine the analysis."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
